{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae3d4bc",
   "metadata": {},
   "source": [
    "AutoGluon - Predicción de ventas (tn) por producto para febrero 2020"
   ]
  },
  {
   "cell_type": "code",
   "id": "8f52d34a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:27.060209Z",
     "start_time": "2025-07-20T19:29:26.263989Z"
    }
   },
   "source": [
    "# 📦 1. Importar librerías\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a67eb1bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:37.829710Z",
     "start_time": "2025-07-20T19:29:27.070671Z"
    }
   },
   "source": [
    "# 💬 Instalar AutoGluon y kaggle si es necesario\n",
    "%pip install autogluon.timeseries\n",
    "%pip install kaggle\n",
    "\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "from autogluon.common import space as ag_space"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autogluon.timeseries in c:\\proyectos\\em\\.venv\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (1.5.1)\n",
      "Requirement already satisfied: numpy<2.3.0,>=1.25.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.1.3)\n",
      "Requirement already satisfied: scipy<1.16,>=1.5.4 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (1.15.3)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.2.3)\n",
      "Requirement already satisfied: torch<2.7,>=2.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.6.0)\n",
      "Requirement already satisfied: lightning<2.7,>=2.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.5.2)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.5.2)\n",
      "Requirement already satisfied: transformers<4.50,>=4.38.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.timeseries) (4.49.0)\n",
      "Requirement already satisfied: accelerate<2.0,>=0.34.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (1.8.1)\n",
      "Requirement already satisfied: gluonts<0.17,>=0.15.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (0.16.2)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (3.5)\n",
      "Requirement already satisfied: statsforecast<2.0.2,>=1.7.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.0.1)\n",
      "Requirement already satisfied: mlforecast<0.14,>0.13 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (0.13.6)\n",
      "Requirement already satisfied: utilsforecast<0.2.11,>=0.2.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (0.2.10)\n",
      "Requirement already satisfied: coreforecast<0.0.16,>=0.0.12 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (0.0.15)\n",
      "Requirement already satisfied: fugue>=0.9.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (4.67.1)\n",
      "Requirement already satisfied: orjson~=3.9 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (3.10.18)\n",
      "Requirement already satisfied: tensorboard<3,>=2.9 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (2.19.0)\n",
      "Requirement already satisfied: autogluon.core==1.3.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.3.1)\n",
      "Requirement already satisfied: autogluon.common==1.3.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (1.3.1)\n",
      "Requirement already satisfied: autogluon.features==1.3.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.timeseries) (1.3.1)\n",
      "Requirement already satisfied: autogluon.tabular==1.3.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (1.3.1)\n",
      "Requirement already satisfied: boto3<2,>=1.10 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.common==1.3.1->autogluon.timeseries) (1.39.4)\n",
      "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.common==1.3.1->autogluon.timeseries) (7.0.0)\n",
      "Requirement already satisfied: scikit-learn<1.7.0,>=1.4.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.6.1)\n",
      "Requirement already satisfied: requests in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2.32.4)\n",
      "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (3.10.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.core[raytune]==1.3.1->autogluon.timeseries) (20.0.0)\n",
      "Requirement already satisfied: ray<2.45,>=2.10.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2.44.1)\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.2.7)\n",
      "Requirement already satisfied: catboost<1.3,>=1.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (1.2.8)\n",
      "Requirement already satisfied: lightgbm<4.7,>=4.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (4.6.0)\n",
      "Requirement already satisfied: xgboost<3.1,>=2.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (3.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from accelerate<2.0,>=0.34.0->autogluon.timeseries) (24.2)\n",
      "Requirement already satisfied: pyyaml in c:\\proyectos\\em\\.venv\\lib\\site-packages (from accelerate<2.0,>=0.34.0->autogluon.timeseries) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from accelerate<2.0,>=0.34.0->autogluon.timeseries) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from accelerate<2.0,>=0.34.0->autogluon.timeseries) (0.5.3)\n",
      "Requirement already satisfied: triad>=0.9.7 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from fugue>=0.9.0->autogluon.timeseries) (0.9.8)\n",
      "Requirement already satisfied: adagio>=0.2.4 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from fugue>=0.9.0->autogluon.timeseries) (0.2.6)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries) (2.11.7)\n",
      "Requirement already satisfied: toolz~=0.10 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries) (4.14.1)\n",
      "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (2025.3.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from lightning<2.7,>=2.2->autogluon.timeseries) (0.14.3)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from lightning<2.7,>=2.2->autogluon.timeseries) (1.7.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\proyectos\\em\\.venv\\lib\\site-packages (from mlforecast<0.14,>0.13->autogluon.timeseries) (3.1.1)\n",
      "Requirement already satisfied: numba in c:\\proyectos\\em\\.venv\\lib\\site-packages (from mlforecast<0.14,>0.13->autogluon.timeseries) (0.61.2)\n",
      "Requirement already satisfied: optuna in c:\\proyectos\\em\\.venv\\lib\\site-packages (from mlforecast<0.14,>0.13->autogluon.timeseries) (4.4.0)\n",
      "Requirement already satisfied: window-ops in c:\\proyectos\\em\\.venv\\lib\\site-packages (from mlforecast<0.14,>0.13->autogluon.timeseries) (0.0.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.timeseries) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.timeseries) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.timeseries) (2025.2)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries) (0.14.5)\n",
      "Requirement already satisfied: threadpoolctl>=3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (2.3.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (1.73.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (3.8.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (5.29.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (80.9.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.timeseries) (3.1.3)\n",
      "Requirement already satisfied: filelock in c:\\proyectos\\em\\.venv\\lib\\site-packages (from torch<2.7,>=2.2->autogluon.timeseries) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from torch<2.7,>=2.2->autogluon.timeseries) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from torch<2.7,>=2.2->autogluon.timeseries) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from sympy==1.13.1->torch<2.7,>=2.2->autogluon.timeseries) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tqdm<5,>=4.38->autogluon.timeseries) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.timeseries) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.timeseries) (0.21.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.timeseries) (0.2.0)\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.4 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from boto3<2,>=1.10->autogluon.common==1.3.1->autogluon.timeseries) (1.39.4)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from boto3<2,>=1.10->autogluon.common==1.3.1->autogluon.timeseries) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from boto3<2,>=1.10->autogluon.common==1.3.1->autogluon.timeseries) (0.13.0)\n",
      "Requirement already satisfied: graphviz in c:\\proyectos\\em\\.venv\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (0.21)\n",
      "Requirement already satisfied: plotly in c:\\proyectos\\em\\.venv\\lib\\site-packages (from catboost<1.3,>=1.2->autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (6.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (3.12.14)\n",
      "Requirement already satisfied: future in c:\\proyectos\\em\\.venv\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.0.0)\n",
      "Requirement already satisfied: py4j in c:\\proyectos\\em\\.venv\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.10.9.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (3.2.3)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from numba->mlforecast<0.14,>0.13->autogluon.timeseries) (0.44.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries) (0.4.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (8.2.1)\n",
      "Requirement already satisfied: jsonschema in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.1.1)\n",
      "Requirement already satisfied: aiosignal in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.4.0)\n",
      "Requirement already satisfied: frozenlist in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.7.0)\n",
      "Requirement already satisfied: aiohttp_cors in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.8.1)\n",
      "Requirement already satisfied: colorful in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.5.7)\n",
      "Requirement already satisfied: py-spy>=0.4.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.4.0)\n",
      "Requirement already satisfied: opencensus in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.11.4)\n",
      "Requirement already satisfied: prometheus_client>=0.7.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.22.1)\n",
      "Requirement already satisfied: smart_open in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (7.3.0.post1)\n",
      "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (20.31.2)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2.6.4)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries) (1.0.1)\n",
      "Requirement already satisfied: fs in c:\\proyectos\\em\\.venv\\lib\\site-packages (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries) (2.4.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<3,>=2.9->autogluon.timeseries) (3.0.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries) (1.16.4)\n",
      "Requirement already satisfied: colorlog in c:\\proyectos\\em\\.venv\\lib\\site-packages (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries) (6.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries) (2.0.41)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from requests->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from requests->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from requests->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from requests->autogluon.core==1.3.1->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2025.7.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (25.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning<2.7,>=2.2->autogluon.timeseries) (1.20.1)\n",
      "Requirement already satisfied: Mako in c:\\proyectos\\em\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna->mlforecast<0.14,>0.13->autogluon.timeseries) (1.3.10)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.14,>0.13->autogluon.timeseries) (3.2.3)\n",
      "Requirement already satisfied: distlib<1,>=0.3.7 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.3.9)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (4.3.8)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries) (1.4.4)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from jsonschema->ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from jsonschema->ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from jsonschema->ray<2.45,>=2.10.0->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.26.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2.25.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[catboost,lightgbm,xgboost]==1.3.1->autogluon.timeseries) (1.46.0)\n",
      "Requirement already satisfied: wrapt in c:\\proyectos\\em\\.venv\\lib\\site-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.17.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.70.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (1.26.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (2.40.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (4.9.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"raytune\"->autogluon.core[raytune]==1.3.1->autogluon.timeseries) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\proyectos\\em\\.venv\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (2025.7.9)\n",
      "Requirement already satisfied: charset-normalizer in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\proyectos\\em\\.venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\proyectos\\em\\.venv\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Proyectos\\EM\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "74387549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:40.973718Z",
     "start_time": "2025-07-20T19:29:38.930747Z"
    }
   },
   "source": [
    "# 📄 2. Cargar datasets\n",
    "df_sellin = pd.read_csv(\"sell-in.txt\", sep=\"\\t\")\n",
    "df_productos = pd.read_csv(\"tb_productos.txt\", sep=\"\\t\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "e14417ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:41.077606Z",
     "start_time": "2025-07-20T19:29:41.004414Z"
    }
   },
   "source": [
    "# 📄 Leer lista de productos a predecir\n",
    "with open(\"productos_pred.txt\", \"r\") as f:\n",
    "    product_ids = [int(line.strip()) for line in f if line.strip().isdigit()]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b1527b4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:41.280457Z",
     "start_time": "2025-07-20T19:29:41.146730Z"
    }
   },
   "source": [
    "# 🧹 3. Preprocesamiento\n",
    "# Convertir periodo a datetime\n",
    "df_sellin['timestamp'] = pd.to_datetime(df_sellin['periodo'], format='%Y%m')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "1083376b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:41.584902Z",
     "start_time": "2025-07-20T19:29:41.321665Z"
    }
   },
   "source": [
    "# Filtrar hasta dic 2019 y productos requeridos\n",
    "df_filtered = df_sellin[\n",
    "    (df_sellin['timestamp'] <= '2019-12-01') &\n",
    "    (df_sellin['product_id'].isin(product_ids))\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.126709Z",
     "start_time": "2025-07-20T19:29:41.639163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Agregar tn por periodo, cliente y producto\n",
    "df_grouped = df_filtered.groupby(['timestamp', 'customer_id', 'product_id'], as_index=False)['tn'].sum()"
   ],
   "id": "bb3c4bac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.405939Z",
     "start_time": "2025-07-20T19:29:43.156502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Agregar tn total por periodo y producto\n",
    "df_monthly_product = df_grouped.groupby(['timestamp', 'product_id'], as_index=False)['tn'].sum()"
   ],
   "id": "3df0c480",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.441785Z",
     "start_time": "2025-07-20T19:29:43.436002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Agregar columna 'item_id' para AutoGluon\n",
    "df_monthly_product['item_id'] = df_monthly_product['product_id']"
   ],
   "id": "065d2ca2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.530289Z",
     "start_time": "2025-07-20T19:29:43.482843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ⏰ 4. Crear TimeSeriesDataFrame\n",
    "ts_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df_monthly_product,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")"
   ],
   "id": "eb4e2dfb",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.719770Z",
     "start_time": "2025-07-20T19:29:43.596274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Completar valores faltantes\n",
    "ts_data = ts_data.fill_missing_values()\n",
    "\n",
    "# Convertir columnas numéricas float64 a float32\n",
    "def convert_float64_to_float32(df):\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        df[col] = df[col].astype('float32')\n",
    "    return df\n",
    "\n",
    "# Aplicar conversión a los dataframes relevantes\n",
    "df_sellin = convert_float64_to_float32(df_sellin)\n",
    "df_productos = convert_float64_to_float32(df_productos)\n",
    "df_grouped = convert_float64_to_float32(df_grouped) if 'df_grouped' in locals() else None\n",
    "df_monthly_product = convert_float64_to_float32(df_monthly_product) if 'df_monthly_product' in locals() else None\n",
    "\n",
    "# 🔍 Validación de datos antes del entrenamiento\n",
    "print(\"🔍 Validando datos de entrada...\")\n",
    "print(f\"📊 Forma de los datos: {ts_data.shape}\")\n",
    "print(f\"📅 Rango de fechas: {ts_data.index.get_level_values('timestamp').min()} - {ts_data.index.get_level_values('timestamp').max()}\")\n",
    "print(f\"🏷️ Número de productos únicos: {ts_data.index.get_level_values('item_id').nunique()}\")\n",
    "print(f\"📈 Valores nulos en target: {ts_data['tn'].isnull().sum()}\")\n",
    "\n",
    "# Verificar que tenemos suficientes datos\n",
    "if ts_data.empty:\n",
    "    raise ValueError(\"❌ Error: Los datos están vacíos\")\n",
    "if ts_data['tn'].isnull().all():\n",
    "    raise ValueError(\"❌ Error: Todos los valores target son nulos\")\n",
    "if ts_data.index.get_level_values('item_id').nunique() == 0:\n",
    "    raise ValueError(\"❌ Error: No hay productos en los datos\")\n",
    "\n",
    "print(\"✅ Validación de datos completada exitosamente\")"
   ],
   "id": "ddac4147",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Validando datos de entrada...\n",
      "📊 Forma de los datos: (22349, 2)\n",
      "📅 Rango de fechas: 2017-01-01 00:00:00 - 2019-12-01 00:00:00\n",
      "🏷️ Número de productos únicos: 780\n",
      "📈 Valores nulos en target: 0\n",
      "✅ Validación de datos completada exitosamente\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.773767Z",
     "start_time": "2025-07-20T19:29:43.762100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 🔧 5. Funciones auxiliares para el bucle iterativo\n",
    "def get_kaggle_score():\n",
    "    \"\"\"Obtiene el score más reciente de Kaggle\"\"\"\n",
    "    try:\n",
    "        output = os.popen('kaggle competitions submissions -c labo-iii-edicion-2025-v').read()\n",
    "        lines = output.strip().split('\\n')\n",
    "        if len(lines) > 2:\n",
    "            # La segunda línea contiene la submission más reciente\n",
    "            recent_line = lines[2]\n",
    "            print(lines[2])\n",
    "            # Extraer el score con un patrón más robusto\n",
    "            # Buscar números decimales que podrían ser el score\n",
    "            score_matches = re.findall(r'(\\d+\\.\\d+)', recent_line)\n",
    "            if score_matches:\n",
    "                # Tomar el último número decimal encontrado (generalmente es el score)\n",
    "                return float(score_matches[-1])\n",
    "            # Si no hay decimales, buscar números enteros\n",
    "            int_matches = re.findall(r'\\b(\\d+)\\b', recent_line)\n",
    "            if int_matches:\n",
    "                return float(int_matches[-1])\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error obteniendo score de Kaggle: {e}\")\n",
    "    return None"
   ],
   "id": "1df4828122347768",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:43.884853Z",
     "start_time": "2025-07-20T19:29:43.868457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def submit_to_kaggle(resultado, iteration):\n",
    "    \"\"\"Sube predicción a Kaggle y retorna el score\"\"\"\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_filename = f\"predicciones_iter_{iteration}_{timestamp_str}.csv\"\n",
    "    resultado.to_csv(output_filename, index=False)\n",
    "\n",
    "    message = f\"Iteración {iteration} - Mejora automática {timestamp_str}\"\n",
    "    os.system(f'kaggle competitions submit -c labo-iii-edicion-2025-v -f {output_filename} -m \"{message}\"')\n",
    "\n",
    "    # Esperar más tiempo para que Kaggle procese\n",
    "    print(f\"⏳ Esperando 3 minutos para que Kaggle procese la submission...\")\n",
    "    time.sleep(180)  # Incrementar a 3 minutos\n",
    "    return get_kaggle_score()"
   ],
   "id": "48089ac21afce1cb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T19:29:44.034256Z",
     "start_time": "2025-07-20T19:29:43.972908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_improved_hyperparameters(iteration, best_score, current_score):\n",
    "    \"\"\"Ajusta hiperparámetros basándose en el rendimiento\"\"\"\n",
    "    import random\n",
    "\n",
    "    # Print información de estado actual\n",
    "    print(f\"🔧 Ajustando hiperparámetros para iteración {iteration}\")\n",
    "    print(f\"📊 Score actual: {current_score if current_score else 'N/A'}\")\n",
    "    print(f\"🏆 Mejor score hasta ahora: {best_score if best_score != float('inf') else 'N/A'}\")\n",
    "\n",
    "    # Determinar si vamos mejorando\n",
    "    improving = False\n",
    "    if current_score and best_score != float('inf'):\n",
    "        improving = current_score < best_score\n",
    "        improvement_diff = best_score - current_score if improving else current_score - best_score\n",
    "        if improving:\n",
    "            print(f\"📈 Tendencia: MEJORANDO (diferencia: {improvement_diff:.6f}) - Explorando modelos más complejos\")\n",
    "        else:\n",
    "            print(f\"📉 Tendencia: SIN MEJORAR (diferencia: {improvement_diff:.6f}) - Ajustando estrategia\")\n",
    "    else:\n",
    "        print(\"🎯 Primera iteración - Explorando configuración base\")\n",
    "\n",
    "    # Acceder a variables globales para detectar estancamiento\n",
    "    global iterations_without_improvement\n",
    "    current_stagnation = iterations_without_improvement if 'iterations_without_improvement' in globals() else 0\n",
    "\n",
    "    if current_stagnation > 0:\n",
    "        print(f\"🔄 Detectado estancamiento de {current_stagnation} iteraciones - Aplicando cambios DRÁSTICOS\")\n",
    "\n",
    "    # Usar iteración y estancamiento para cambios MÁS AGRESIVOS\n",
    "    random.seed(iteration * 123 + current_stagnation * 456)  # Más variación en la semilla\n",
    "\n",
    "    # RANGOS DRAMÁTICAMENTE EXPANDIDOS - Siempre usar rangos amplios\n",
    "    epochs_range = [50, 100, 150, 200, 250, 300, 400, 500, 600]  # Épocas mucho más altas\n",
    "    lr_range = [1e-1, 5e-2, 1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 1e-6]  # Rangos extremos\n",
    "    hidden_sizes = [64, 128, 256, 512, 768, 1024, 1536, 2048]  # Tamaños más grandes\n",
    "    layers_range = [2, 3, 4, 5, 6, 7, 8, 10, 12]  # Más capas profundas\n",
    "    dropout_range = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]  # Rango completo\n",
    "\n",
    "    # Con estancamiento, usar TODOS los valores disponibles\n",
    "    if current_stagnation > 3:\n",
    "        print(\"💥 MODO EXTREMO: Usando rangos máximos por estancamiento\")\n",
    "        epochs_range.extend([700, 800, 1000])  # Épocas extremas\n",
    "        hidden_sizes.extend([3072, 4096])  # Tamaños gigantes\n",
    "        layers_range.extend([15, 20])  # Capas muy profundas\n",
    "        lr_range.extend([2e-1, 5e-6, 1e-7])  # LR extremos\n",
    "\n",
    "    # Seleccionar MUCHAS más combinaciones - mínimo 5-8 opciones\n",
    "    variation_factor = max(3, current_stagnation)\n",
    "    epoch_choices = random.sample(epochs_range, min(6 + variation_factor, len(epochs_range)))\n",
    "    lr_choices = random.sample(lr_range, min(6 + variation_factor, len(lr_range)))\n",
    "    hidden_choices = random.sample(hidden_sizes, min(5 + variation_factor, len(hidden_sizes)))\n",
    "    layer_choices = random.sample(layers_range, min(5 + variation_factor, len(layers_range)))\n",
    "    dropout_choices = random.sample(dropout_range, min(5 + variation_factor, len(dropout_range)))\n",
    "\n",
    "    print(f\"⚙️ Epochs seleccionados: {sorted(epoch_choices)}\")\n",
    "    print(f\"⚙️ Learning rates: {sorted(lr_choices, reverse=True)}\")\n",
    "    print(f\"⚙️ Hidden sizes: {sorted(hidden_choices)}\")\n",
    "    print(f\"⚙️ Layers: {sorted(layer_choices)}\")\n",
    "    print(f\"⚙️ Dropout rates: {sorted(dropout_choices)}\")\n",
    "\n",
    "    # Configuraciones específicas por modelo con MÁXIMA variación\n",
    "    deepar_epochs = random.sample([100, 150, 200, 300, 400, 500, 600, 800], min(6, 8))\n",
    "    tft_epochs = random.sample([50, 100, 150, 200, 300, 400, 500], min(5, 7))\n",
    "    patch_epochs = random.sample([50, 100, 150, 200, 300, 400, 500], min(5, 7))\n",
    "\n",
    "    # Variaciones EXTREMAS en patch lengths y strides\n",
    "    patch_lens = random.sample([4, 8, 12, 16, 24, 32, 48, 64, 96, 128], min(6, 10))\n",
    "    strides = random.sample([2, 4, 6, 8, 12, 16, 24, 32, 48, 64], min(6, 10))\n",
    "    attention_heads = random.sample([4, 6, 8, 12, 16, 20, 24, 32], min(5, 8))\n",
    "\n",
    "    # Configuraciones base SIEMPRE con modelos complejos\n",
    "    base_hyperparameters = {\n",
    "        'DeepAR': {\n",
    "            'epochs': ag_space.Categorical(*deepar_epochs),\n",
    "            'learning_rate': ag_space.Categorical(*lr_choices),\n",
    "            'hidden_size': ag_space.Categorical(*hidden_choices),\n",
    "            'num_layers': ag_space.Categorical(*layer_choices),\n",
    "            'dropout_rate': ag_space.Categorical(*dropout_choices)\n",
    "        },\n",
    "        'TemporalFusionTransformer': {\n",
    "            'epochs': ag_space.Categorical(*tft_epochs),\n",
    "            'learning_rate': ag_space.Categorical(*lr_choices),\n",
    "            'hidden_size': ag_space.Categorical(*hidden_choices),\n",
    "            'num_attention_heads': ag_space.Categorical(*attention_heads)\n",
    "        },\n",
    "        'PatchTST': {\n",
    "            'epochs': ag_space.Categorical(*patch_epochs),\n",
    "            'learning_rate': ag_space.Categorical(*lr_choices),\n",
    "            'patch_len': ag_space.Categorical(*patch_lens),\n",
    "            'stride': ag_space.Categorical(*strides)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # SIEMPRE agregar modelos experimentales desde iteración 2\n",
    "    if iteration >= 2:\n",
    "        print(\"🚀 Agregando TODOS los modelos experimentales disponibles\")\n",
    "\n",
    "        # TiDE con configuraciones agresivas\n",
    "        tide_epochs = random.sample([150, 200, 300, 400, 500, 600, 800], min(5, 7))\n",
    "        tide_hidden = random.sample([512, 768, 1024, 1536, 2048, 3072], min(5, 6))\n",
    "        tide_layers = random.sample([4, 6, 8, 10, 12, 15], min(4, 6))\n",
    "\n",
    "        base_hyperparameters.update({\n",
    "            'TiDE': {\n",
    "                'epochs': ag_space.Categorical(*tide_epochs),\n",
    "                'learning_rate': ag_space.Categorical(*lr_choices),\n",
    "                'hidden_size': ag_space.Categorical(*tide_hidden),\n",
    "                'num_layers': ag_space.Categorical(*tide_layers),\n",
    "                'dropout': ag_space.Categorical(*dropout_choices)\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # Chronos con TODOS los tamaños\n",
    "        chronos_sizes = ['tiny', 'mini', 'small', 'base', 'large'] if iteration > 5 else ['tiny', 'mini', 'small', 'base']\n",
    "        base_hyperparameters.update({\n",
    "            'Chronos': {\n",
    "                'model_size': ag_space.Categorical(*chronos_sizes)\n",
    "            }\n",
    "        })\n",
    "\n",
    "        # NPTS con contextos variables\n",
    "        context_lengths = random.sample([24, 36, 48, 60, 72, 96, 120], min(5, 7))\n",
    "        base_hyperparameters.update({\n",
    "            'NPTS': {\n",
    "                'context_length': ag_space.Categorical(*context_lengths)\n",
    "            }\n",
    "        })\n",
    "\n",
    "        print(f\"   ├─ TiDE epochs: {sorted(tide_epochs)}\")\n",
    "        print(f\"   ├─ TiDE hidden sizes: {sorted(tide_hidden)}\")\n",
    "        print(f\"   ├─ Chronos sizes: {chronos_sizes}\")\n",
    "        print(f\"   └─ NPTS context lengths: {sorted(context_lengths)}\")\n",
    "\n",
    "    # Modelos baseline con configuraciones mejoradas\n",
    "    baseline_models = ['AutoETS', 'DynamicOptimizedTheta', 'SeasonalNaive', 'DirectTabular', 'RecursiveTabular']\n",
    "    base_hyperparameters.update({\n",
    "        'AutoETS': {},\n",
    "        'DynamicOptimizedTheta': {},\n",
    "        'SeasonalNaive': {},\n",
    "        'DirectTabular': {'ag_args_fit': {'num_gpus': 0, 'verbosity': 2}},\n",
    "        'RecursiveTabular': {'ag_args_fit': {'num_gpus': 0, 'verbosity': 2}}\n",
    "    })\n",
    "\n",
    "    print(f\"🎯 Total de modelos configurados: {len(base_hyperparameters)}\")\n",
    "    print(f\"📋 Modelos complejos: {[k for k in base_hyperparameters.keys() if k not in baseline_models]}\")\n",
    "    print(f\"📋 Modelos baseline: {baseline_models}\")\n",
    "    print(f\"🔥 Nivel de AGRESIVIDAD MÁXIMA aplicado: {min(current_stagnation + 5, 10)}/10\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return base_hyperparameters"
   ],
   "id": "ef4ebc69ffdb3f16",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-20T19:29:44.101552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 🔄 6. Bucle iterativo de mejora\n",
    "print(\"🚀 Iniciando bucle iterativo de mejora de modelo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Variables para tracking\n",
    "best_score = float('inf')\n",
    "best_iteration = 0\n",
    "scores_history = []\n",
    "models_history = []\n",
    "iterations_without_improvement = 0  # Contador de iteraciones sin mejora\n",
    "last_improvement_iteration = 0  # Última iteración con mejora\n",
    "\n",
    "for iteration in range(1, 81):  # 80 iteraciones\n",
    "    print(f\"\\n🔄 ITERACIÓN {iteration}/80\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    try:\n",
    "        # Crear predictor para esta iteración\n",
    "        predictor = TimeSeriesPredictor(\n",
    "            prediction_length=2,\n",
    "            target='tn',\n",
    "            freq='MS',\n",
    "            eval_metric='MASE',\n",
    "            path=f'AutogluonModels/iteration_{iteration}'\n",
    "        )\n",
    "\n",
    "        # PRIMERA ITERACIÓN: Usar configuración por defecto SIN hiperparámetros específicos\n",
    "        if iteration == 1:\n",
    "            print(\"🎯 PRIMERA ITERACIÓN - Entrenamiento con configuración por defecto\")\n",
    "            print(\"📋 Usando modelos base de AutoGluon sin hiperparámetros específicos\")\n",
    "\n",
    "            # Configuración simple para la primera iteración\n",
    "            hyperparameters = None  # Usar defaults de AutoGluon\n",
    "            hyperparameter_tune_kwargs = None  # Sin búsqueda de hiperparámetros\n",
    "\n",
    "            # Tiempo base más corto para la primera iteración (1 hora)\n",
    "            adjusted_time = 3600  # 1 hora\n",
    "            print(f\"⏰ Tiempo de entrenamiento inicial: {adjusted_time/3600:.1f} hora\")\n",
    "\n",
    "        else:\n",
    "            # ITERACIONES 2+: Usar lógica de hiperparámetros existente\n",
    "            print(f\"🔧 ITERACIÓN {iteration} - Optimización avanzada con hiperparámetros\")\n",
    "\n",
    "            # Obtener hiperparámetros mejorados\n",
    "            current_score = scores_history[-1] if scores_history else None\n",
    "            hyperparameters = get_improved_hyperparameters(iteration, best_score, current_score)\n",
    "\n",
    "            # Ajustar trials basándose en las iteraciones sin mejora - MÁS AGRESIVO\n",
    "            base_trials = min(10 + iteration * 5, 150)  # Incrementar trials base significativamente\n",
    "            if iterations_without_improvement > 3:\n",
    "                # Incrementar trials DRAMÁTICAMENTE si no hay mejoras\n",
    "                trials_multiplier = min(3 + (iterations_without_improvement // 2), 6)\n",
    "                adjusted_trials = min(base_trials * trials_multiplier, 300)  # Hasta 300 trials\n",
    "                print(f\"⚡ Sin mejoras por {iterations_without_improvement} iteraciones - Incrementando trials a {adjusted_trials}\")\n",
    "            else:\n",
    "                adjusted_trials = base_trials\n",
    "\n",
    "            # Configurar búsqueda de hiperparámetros\n",
    "            hyperparameter_tune_kwargs = {\n",
    "                'num_trials': adjusted_trials,\n",
    "                'scheduler': 'local',\n",
    "                'searcher': 'random'\n",
    "            }\n",
    "\n",
    "            print(f\"📊 Entrenando con {len(hyperparameters)} modelos...\")\n",
    "            print(f\"🔍 Trials de hiperparámetros: {hyperparameter_tune_kwargs['num_trials']}\")\n",
    "\n",
    "            # TIEMPOS DE ENTRENAMIENTO DRAMÁTICAMENTE MÁS LARGOS\n",
    "            # Tiempo base mucho más alto: mínimo 4 horas, máximo 24 horas\n",
    "            base_time_hours = 4 + (iteration * 0.5)  # Incrementar 30 min por iteración\n",
    "            base_time = int(base_time_hours * 3600)  # Convertir a segundos\n",
    "\n",
    "            # Multiplicadores agresivos por estancamiento\n",
    "            if iterations_without_improvement > 8:\n",
    "                time_multiplier = 5.0  # 5x más tiempo si está muy estancado\n",
    "                adjusted_time = min(int(base_time * time_multiplier), 24 * 3600)  # Máximo 24 horas\n",
    "                print(f\"💥 ESTANCAMIENTO EXTREMO - Tiempo de entrenamiento: {adjusted_time/3600:.1f} horas\")\n",
    "            elif iterations_without_improvement > 5:\n",
    "                time_multiplier = 3.0  # 3x más tiempo si está estancado\n",
    "                adjusted_time = min(int(base_time * time_multiplier), 20 * 3600)  # Máximo 20 horas\n",
    "                print(f\"🚨 ESTANCAMIENTO PROLONGADO - Tiempo de entrenamiento: {adjusted_time/3600:.1f} horas\")\n",
    "            elif iterations_without_improvement > 2:\n",
    "                time_multiplier = 2.0  # 2x más tiempo si no mejora\n",
    "                adjusted_time = min(int(base_time * time_multiplier), 16 * 3600)  # Máximo 16 horas\n",
    "                print(f\"⚡ Sin mejoras detectadas - Tiempo de entrenamiento: {adjusted_time/3600:.1f} horas\")\n",
    "            else:\n",
    "                adjusted_time = base_time\n",
    "                print(f\"⏰ Tiempo de entrenamiento base: {adjusted_time/3600:.1f} horas\")\n",
    "\n",
    "        print(f\"🕐 Tiempo estimado de finalización: {(datetime.now() + pd.Timedelta(seconds=adjusted_time)).strftime('%H:%M:%S')}\")\n",
    "        print(f\"📅 Fecha estimada de finalización: {(datetime.now() + pd.Timedelta(seconds=adjusted_time)).strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        # Entrenar modelo con configuración específica por iteración\n",
    "        start_time = time.time()\n",
    "\n",
    "        if iteration == 1:\n",
    "            # Primera iteración: entrenamiento simple\n",
    "            predictor.fit(\n",
    "                train_data=ts_data,\n",
    "                time_limit=adjusted_time\n",
    "            )\n",
    "        else:\n",
    "            # Iteraciones 2+: entrenamiento con hiperparámetros\n",
    "            predictor.fit(\n",
    "                train_data=ts_data,\n",
    "                hyperparameters=hyperparameters,\n",
    "                hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    "                time_limit=adjusted_time\n",
    "            )\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        print(f\"⏱️ Tiempo de entrenamiento REAL: {training_time/3600:.2f} horas ({training_time/60:.1f} minutos)\")\n",
    "\n",
    "        # Comparar tiempo real vs planificado\n",
    "        time_efficiency = (training_time / adjusted_time) * 100\n",
    "        print(f\"📊 Eficiencia de tiempo: {time_efficiency:.1f}% del tiempo asignado\")\n",
    "\n",
    "        if time_efficiency < 50:\n",
    "            print(\"⚠️ El entrenamiento terminó mucho antes del tiempo asignado - considera modelos más complejos\")\n",
    "        elif time_efficiency > 95:\n",
    "            print(\"✅ Uso completo del tiempo asignado - entrenamiento exhaustivo\")\n",
    "\n",
    "        # Generar predicción\n",
    "        print(\"🔮 Generando predicciones...\")\n",
    "        forecast = predictor.predict(ts_data)\n",
    "\n",
    "        # Verificar que forecast contiene datos válidos\n",
    "        if forecast is None or 'mean' not in forecast:\n",
    "            print(\"❌ Error: No se pudo generar predicción válida\")\n",
    "            scores_history.append(None)\n",
    "            models_history.append({\n",
    "                'iteration': iteration,\n",
    "                'score': None,\n",
    "                'training_time': training_time,\n",
    "                'best_model': 'Error',\n",
    "                'error': 'No prediction generated'\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Procesar resultados\n",
    "        resultado = forecast['mean'].reset_index()\n",
    "\n",
    "        # Verificar que tenemos datos para febrero 2020\n",
    "        feb_2020_data = resultado[resultado['timestamp'] == '2020-02-01']\n",
    "        if feb_2020_data.empty:\n",
    "            print(\"⚠️ Advertencia: No hay predicciones para febrero 2020, usando primer mes disponible\")\n",
    "            # Usar el primer mes disponible\n",
    "            unique_timestamps = resultado['timestamp'].unique()\n",
    "            if len(unique_timestamps) > 0:\n",
    "                feb_2020_data = resultado[resultado['timestamp'] == unique_timestamps[0]]\n",
    "\n",
    "        if feb_2020_data.empty:\n",
    "            print(\"❌ Error: No hay predicciones disponibles\")\n",
    "            scores_history.append(None)\n",
    "            continue\n",
    "\n",
    "        resultado = feb_2020_data[['item_id', 'mean']].copy()\n",
    "        resultado.columns = ['product_id', 'tn']\n",
    "\n",
    "        # Validar que tenemos predicciones válidas\n",
    "        if resultado.empty or resultado['tn'].isna().all():\n",
    "            print(\"❌ Error: Predicciones vacías o inválidas\")\n",
    "            scores_history.append(None)\n",
    "            continue\n",
    "\n",
    "        print(f\"📈 Productos predichos: {len(resultado)}\")\n",
    "        print(f\"📊 Rango de predicciones: {resultado['tn'].min():.2f} - {resultado['tn'].max():.2f}\")\n",
    "\n",
    "        # Subir a Kaggle y obtener score\n",
    "        print(\"⬆️ Subiendo a Kaggle...\")\n",
    "        kaggle_score = submit_to_kaggle(resultado, iteration)\n",
    "\n",
    "        if kaggle_score:\n",
    "            scores_history.append(kaggle_score)\n",
    "            print(f\"🎯 Score obtenido: {kaggle_score}\")\n",
    "\n",
    "            # Verificar si es el mejor score\n",
    "            if kaggle_score < best_score:\n",
    "                best_score = kaggle_score\n",
    "                best_iteration = iteration\n",
    "                last_improvement_iteration = iteration\n",
    "                iterations_without_improvement = 0  # Resetear contador\n",
    "                print(f\"🏆 ¡NUEVO MEJOR SCORE! Mejora: {best_score}\")\n",
    "                print(f\"✨ Reseteando contador de iteraciones sin mejora\")\n",
    "            else:\n",
    "                iterations_without_improvement += 1\n",
    "                print(f\"📉 No mejoró. Mejor score sigue siendo: {best_score} (iteración {best_iteration})\")\n",
    "                print(f\"⏳ Iteraciones sin mejora: {iterations_without_improvement}\")\n",
    "\n",
    "                # Estrategias adicionales cuando no hay mejora\n",
    "                if iterations_without_improvement >= 3:\n",
    "                    print(f\"🔧 Activando estrategias de recuperación (sin mejora por {iterations_without_improvement} iteraciones)\")\n",
    "\n",
    "                if iterations_without_improvement >= 5:\n",
    "                    print(\"🚨 Considerando cambios drásticos en próximas iteraciones\")\n",
    "\n",
    "                if iterations_without_improvement >= 10:\n",
    "                    print(\"💥 Implementando búsqueda exhaustiva - esto puede tomar más tiempo\")\n",
    "        else:\n",
    "            print(\"⚠️ No se pudo obtener score de Kaggle\")\n",
    "            scores_history.append(None)\n",
    "            iterations_without_improvement += 1\n",
    "\n",
    "        # Guardar información del modelo\n",
    "        try:\n",
    "            model_info = predictor.leaderboard()\n",
    "            best_model = model_info.iloc[0]['model'] if not model_info.empty else 'Unknown'\n",
    "            leaderboard_records = model_info.to_dict('records') if not model_info.empty else []\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error obteniendo leaderboard: {e}\")\n",
    "            best_model = 'Unknown'\n",
    "            leaderboard_records = []\n",
    "\n",
    "        models_history.append({\n",
    "            'iteration': iteration,\n",
    "            'score': kaggle_score,\n",
    "            'training_time': training_time,\n",
    "            'best_model': best_model,\n",
    "            'leaderboard': leaderboard_records\n",
    "        })\n",
    "\n",
    "        print(f\"🥇 Mejor modelo local: {best_model}\")\n",
    "\n",
    "        # Guardar progreso\n",
    "        progress_data = {\n",
    "            'scores_history': scores_history,\n",
    "            'models_history': models_history,\n",
    "            'best_score': best_score,\n",
    "            'best_iteration': best_iteration,\n",
    "            'last_updated': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(f'iteration_progress_{datetime.now().strftime(\"%Y%m%d\")}.json', 'w') as f:\n",
    "                json.dump(progress_data, f, indent=2, default=str)\n",
    "            print(f\"💾 Progreso guardado exitosamente\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error guardando progreso: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en iteración {iteration}: {e}\")\n",
    "        scores_history.append(None)\n",
    "        models_history.append({\n",
    "            'iteration': iteration,\n",
    "            'score': None,\n",
    "            'training_time': 0,\n",
    "            'best_model': 'Error',\n",
    "            'error': str(e)\n",
    "        })\n",
    "        continue"
   ],
   "id": "1b68ad41599e2b03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando bucle iterativo de mejora de modelo\n",
      "============================================================\n",
      "\n",
      "🔄 ITERACIÓN 1/80\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 3600s\n",
      "AutoGluon will save models to 'G:\\Mi unidad\\Maestría\\Data Science\\Laboratorio de Implementación III\\Proyectos\\labo3-2025v\\AutogluonModels\\iteration_1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 PRIMERA ITERACIÓN - Entrenamiento con configuración por defecto\n",
      "📋 Usando modelos base de AutoGluon sin hiperparámetros específicos\n",
      "⏰ Tiempo de entrenamiento inicial: 1.0 hora\n",
      "🕐 Tiempo estimado de finalización: 17:29:44\n",
      "📅 Fecha estimada de finalización: 2025-07-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.1\n",
      "Python Version:     3.12.6\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "GPU Count:          0\n",
      "Memory Avail:       4.91 GB / 15.71 GB (31.2%)\n",
      "Disk Space Avail:   20.20 GB / 100.00 GB (20.2%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': MASE,\n",
      " 'freq': 'MS',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 2,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'tn',\n",
      " 'time_limit': 3600,\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'IRREG' has been resampled to frequency 'MS'.\n",
      "Provided train_data has 22375 rows (NaN fraction=0.1%), 780 time series. Median time series length is 36 (min=4, max=36). \n",
      "\tRemoving 46 short time series from train_data. Only series with length >= 7 will be used for training.\n",
      "\tAfter filtering, train_data has 22132 rows (NaN fraction=0.1%), 734 time series. Median time series length is 36 (min=7, max=36). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'tn'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['product_id']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'MASE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-07-20 16:29:52\n",
      "Models that will be trained: ['SeasonalNaive', 'RecursiveTabular', 'DirectTabular', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'ChronosZeroShot[bolt_base]', 'ChronosFineTuned[bolt_small]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'TiDE']\n",
      "Training timeseries model SeasonalNaive. Training for up to 276.1s of the 3589.6s of remaining time.\n",
      "\t-1.3722       = Validation score (-MASE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t5.25    s     = Validation (prediction) runtime\n",
      "Training timeseries model RecursiveTabular. Training for up to 298.7s of the 3584.0s of remaining time.\n",
      "\tTime series in the dataset are too short for chosen differences [12]. Setting differences to [1].\n",
      "\t-1.3903       = Validation score (-MASE)\n",
      "\t3.89    s     = Training runtime\n",
      "\t0.15    s     = Validation (prediction) runtime\n",
      "Training timeseries model DirectTabular. Training for up to 325.4s of the 3579.8s of remaining time.\n",
      "\t-1.3904       = Validation score (-MASE)\n",
      "\t2.58    s     = Training runtime\n",
      "\t0.19    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 357.7s of the 3576.9s of remaining time.\n",
      "\t-1.4146       = Validation score (-MASE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t1.07    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 397.3s of the 3575.5s of remaining time.\n",
      "\t-1.2606       = Validation score (-MASE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t7.90    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 445.9s of the 3567.3s of remaining time.\n",
      "\tWarning: AutoETS\\W0 failed for 29 time series (4.0%). Fallback model SeasonalNaive was used for these time series.\n",
      "\t-1.2549       = Validation score (-MASE)\n",
      "\t0.10    s     = Training runtime\n",
      "\t8.00    s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosZeroShot[bolt_base]. Training for up to 508.4s of the 3559.0s of remaining time.\n",
      "\t-1.2169       = Validation score (-MASE)\n",
      "\t18.81   s     = Training runtime\n",
      "\t15.67   s     = Validation (prediction) runtime\n",
      "Training timeseries model ChronosFineTuned[bolt_small]. Training for up to 587.4s of the 3524.3s of remaining time.\n",
      "\tSkipping covariate_regressor since the dataset contains no covariates or static features.\n",
      "\tFine-tuning on the CPU detected. We recommend using a GPU for faster fine-tuning of Chronos.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 📊 7. Resumen final\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📊 RESUMEN FINAL DE MEJORAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, score in enumerate(scores_history, 1):\n",
    "    if score:\n",
    "        status = \"🏆 MEJOR\" if i == best_iteration else \"\"\n",
    "        print(f\"Iteración {i}: {score} {status}\")\n",
    "    else:\n",
    "        print(f\"Iteración {i}: Sin score\")\n",
    "\n",
    "if best_iteration > 0:\n",
    "    improvement = scores_history[0] - best_score if scores_history[0] else 0\n",
    "    print(f\"\\n🎯 Mejor resultado: Iteración {best_iteration} con score {best_score}\")\n",
    "    if improvement > 0:\n",
    "        print(f\"📈 Mejora total: {improvement:.6f}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No se pudo determinar el mejor modelo\")\n",
    "\n",
    "print(f\"\\n📁 Progreso guardado en: iteration_progress_{datetime.now().strftime('%Y%m%d')}.json\")\n"
   ],
   "id": "a505b11d83ec4971",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
